{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering for Route Recommendations\n",
    "\n",
    "**Purpose:** Cluster all routes into k groups (e.g., k=10) to enable \"curveball\" recommendations from different clusters.\n",
    "\n",
    "**Goal:** \n",
    "- Find optimal k (number of clusters)\n",
    "- Cluster routes by similarity\n",
    "- Profile each cluster to enable manual labeling (e.g., 'long mountain ride', 'short city ride')\n",
    "- Save model for production use\n",
    "\n",
    "**Use Case:** When a user uploads a route, serve:\n",
    "- 5 nearest neighbors (KNN) from same/similar characteristics\n",
    "- 1 \"curveball\" from a different cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score\n",
    ")\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the engineered data\n",
    "df = pd.read_csv(\"../../api_faf/app/Data_Engineered.csv\")\n",
    "print(f\"‚úÖ Loaded {len(df):,} routes\")\n",
    "print(f\"   Columns: {df.shape[1]}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è  Missing values found:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"‚úÖ No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Features (Same as KNN Model)\n",
    "\n",
    "Use the same scaling approach as the KNN model for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix (exclude id, name, region)\n",
    "X = df.drop(['id', 'name', 'region'], axis=1)\n",
    "feature_cols = X.columns.tolist()\n",
    "\n",
    "print(f\"‚úÖ Feature matrix created: {X.shape}\")\n",
    "print(f\"\\nüìä Features ({len(feature_cols)}):\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply same scaling as KNN training\n",
    "scaler = ColumnTransformer(transformers=[\n",
    "    ('standard', StandardScaler(), [\n",
    "        'distance_m', 'duration_s', 'ascent_m', 'descent_m', \n",
    "        'Turn_Density', 'steps', 'turns'\n",
    "    ]),\n",
    "    ('minmax', MinMaxScaler(), [\n",
    "        'Cycleway', 'on_road', 'off_road', 'Gravel_Tracks', 'Paved_Paths', \n",
    "        'Other', 'Unknown Surface', 'Paved_Road', 'Pedestrian', 'Unknown_Way', \n",
    "        'Cycle Track', 'Main Road', 'Steep Section', 'Moderate Section', \n",
    "        'Flat Section', 'Downhill Section', 'Steep Downhill Section'\n",
    "    ]),\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"‚úÖ Features scaled: {X_scaled.shape}\")\n",
    "print(f\"   StandardScaler: 7 features (distance, duration, elevation, turns)\")\n",
    "print(f\"   MinMaxScaler: 17 features (surface types, gradients)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means Parameter Search\n",
    "\n",
    "Test different values of k and initialization methods to find optimal clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "k_values = range(3, 21)  # Test k from 3 to 20\n",
    "init_methods = ['k-means++', 'random']  # Initialization strategies\n",
    "n_init = 20  # Number of times to run k-means with different seeds\n",
    "\n",
    "print(f\"üîç Parameter Search Configuration:\")\n",
    "print(f\"   k values: {list(k_values)}\")\n",
    "print(f\"   Init methods: {init_methods}\")\n",
    "print(f\"   n_init (runs per config): {n_init}\")\n",
    "print(f\"\\n‚è≥ This will test {len(k_values) * len(init_methods)} configurations...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation Metrics\n",
    "\n",
    "We'll use multiple metrics to evaluate clustering quality:\n",
    "\n",
    "1. **Inertia (Within-cluster sum of squares)**: Lower is better. Shows how tight clusters are.\n",
    "2. **Silhouette Score**: Range [-1, 1]. Higher is better. Measures how similar points are to their own cluster vs other clusters.\n",
    "3. **Davies-Bouldin Index**: Lower is better. Measures average similarity between clusters.\n",
    "4. **Calinski-Harabasz Score**: Higher is better. Ratio of between-cluster to within-cluster dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run parameter search\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    for init in init_methods:\n",
    "        print(f\"Testing k={k:2d}, init='{init}'...\", end=' ')\n",
    "        \n",
    "        # Fit k-means\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=k,\n",
    "            init=init,\n",
    "            n_init=n_init,\n",
    "            max_iter=300,\n",
    "            random_state=42\n",
    "        )\n",
    "        labels = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        inertia = kmeans.inertia_\n",
    "        silhouette = silhouette_score(X_scaled, labels, sample_size=10000)  # Sample for speed\n",
    "        davies_bouldin = davies_bouldin_score(X_scaled, labels)\n",
    "        calinski = calinski_harabasz_score(X_scaled, labels)\n",
    "        \n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'init': init,\n",
    "            'inertia': inertia,\n",
    "            'silhouette': silhouette,\n",
    "            'davies_bouldin': davies_bouldin,\n",
    "            'calinski_harabasz': calinski\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úì Silhouette: {silhouette:.4f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n‚úÖ Parameter search complete! Tested {len(results_df)} configurations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results sorted by different metrics\n",
    "print(\"=\" * 100)\n",
    "print(\"TOP 10 CONFIGURATIONS BY SILHOUETTE SCORE (higher is better)\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.sort_values('silhouette', ascending=False).head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP 10 CONFIGURATIONS BY DAVIES-BOULDIN INDEX (lower is better)\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.sort_values('davies_bouldin', ascending=True).head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"TOP 10 CONFIGURATIONS BY CALINSKI-HARABASZ SCORE (higher is better)\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.sort_values('calinski_harabasz', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results\n",
    "\n",
    "Create plots to help identify the optimal k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Elbow Method (Inertia)\n",
    "for init in init_methods:\n",
    "    data = results_df[results_df['init'] == init]\n",
    "    axes[0, 0].plot(data['k'], data['inertia'], marker='o', label=f\"init={init}\")\n",
    "axes[0, 0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Inertia (Within-cluster Sum of Squares)', fontsize=12)\n",
    "axes[0, 0].set_title('Elbow Method: Find the \"Elbow\" Point', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Silhouette Score\n",
    "for init in init_methods:\n",
    "    data = results_df[results_df['init'] == init]\n",
    "    axes[0, 1].plot(data['k'], data['silhouette'], marker='o', label=f\"init={init}\")\n",
    "axes[0, 1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "axes[0, 1].set_title('Silhouette Score (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Plot 3: Davies-Bouldin Index\n",
    "for init in init_methods:\n",
    "    data = results_df[results_df['init'] == init]\n",
    "    axes[1, 0].plot(data['k'], data['davies_bouldin'], marker='o', label=f\"init={init}\")\n",
    "axes[1, 0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Davies-Bouldin Index', fontsize=12)\n",
    "axes[1, 0].set_title('Davies-Bouldin Index (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Calinski-Harabasz Score\n",
    "for init in init_methods:\n",
    "    data = results_df[results_df['init'] == init]\n",
    "    axes[1, 1].plot(data['k'], data['calinski_harabasz'], marker='o', label=f\"init={init}\")\n",
    "axes[1, 1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Calinski-Harabasz Score', fontsize=12)\n",
    "axes[1, 1].set_title('Calinski-Harabasz Score (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kmeans_evaluation_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Plots saved as 'kmeans_evaluation_metrics.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined score ranking\n",
    "# Normalize metrics to [0, 1] scale and combine\n",
    "results_norm = results_df.copy()\n",
    "\n",
    "# Normalize: higher silhouette is better, lower davies_bouldin is better, higher calinski is better\n",
    "results_norm['silhouette_norm'] = (results_norm['silhouette'] - results_norm['silhouette'].min()) / \\\n",
    "                                   (results_norm['silhouette'].max() - results_norm['silhouette'].min())\n",
    "\n",
    "results_norm['davies_bouldin_norm'] = 1 - ((results_norm['davies_bouldin'] - results_norm['davies_bouldin'].min()) / \\\n",
    "                                             (results_norm['davies_bouldin'].max() - results_norm['davies_bouldin'].min()))\n",
    "\n",
    "results_norm['calinski_norm'] = (results_norm['calinski_harabasz'] - results_norm['calinski_harabasz'].min()) / \\\n",
    "                                 (results_norm['calinski_harabasz'].max() - results_norm['calinski_harabasz'].min())\n",
    "\n",
    "# Combined score (equal weights)\n",
    "results_norm['combined_score'] = (results_norm['silhouette_norm'] + \n",
    "                                   results_norm['davies_bouldin_norm'] + \n",
    "                                   results_norm['calinski_norm']) / 3\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"TOP 10 CONFIGURATIONS BY COMBINED SCORE\")\n",
    "print(\"=\" * 100)\n",
    "print(results_norm.sort_values('combined_score', ascending=False)[[\n",
    "    'k', 'init', 'combined_score', 'silhouette', 'davies_bouldin', 'calinski_harabasz'\n",
    "]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select Optimal K and Fit Final Model\n",
    "\n",
    "Based on the evaluation metrics above, select the optimal k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best configuration\n",
    "best_config = results_norm.sort_values('combined_score', ascending=False).iloc[0]\n",
    "optimal_k = int(best_config['k'])\n",
    "optimal_init = best_config['init']\n",
    "\n",
    "print(f\"üèÜ RECOMMENDED CONFIGURATION:\")\n",
    "print(f\"   k = {optimal_k}\")\n",
    "print(f\"   init = '{optimal_init}'\")\n",
    "print(f\"   Combined Score = {best_config['combined_score']:.4f}\")\n",
    "print(f\"\\nüìä Metrics:\")\n",
    "print(f\"   Silhouette Score: {best_config['silhouette']:.4f}\")\n",
    "print(f\"   Davies-Bouldin Index: {best_config['davies_bouldin']:.4f}\")\n",
    "print(f\"   Calinski-Harabasz Score: {best_config['calinski_harabasz']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow manual override if desired\n",
    "# OVERRIDE: Set to None to use recommended k, or set to desired value (e.g., 10)\n",
    "MANUAL_K = None  # Change to 10 if you want to force k=10 for easier labeling\n",
    "\n",
    "if MANUAL_K is not None:\n",
    "    final_k = MANUAL_K\n",
    "    print(f\"‚ö†Ô∏è  MANUAL OVERRIDE: Using k = {final_k} instead of recommended k = {optimal_k}\")\n",
    "else:\n",
    "    final_k = optimal_k\n",
    "    print(f\"‚úÖ Using recommended k = {final_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final k-means model\n",
    "print(f\"\\n‚è≥ Fitting final k-means model with k={final_k}...\")\n",
    "\n",
    "kmeans_final = KMeans(\n",
    "    n_clusters=final_k,\n",
    "    init='k-means++',  # Generally more reliable\n",
    "    n_init=50,  # More runs for final model\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"‚úÖ K-means clustering complete!\")\n",
    "print(f\"\\nüìä Cluster distribution:\")\n",
    "print(df['cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cluster Profiling\n",
    "\n",
    "Analyze each cluster to understand its characteristics and enable manual labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cluster statistics for key features\n",
    "key_features = ['distance_m', 'ascent_m', 'duration_s', 'Turn_Density', \n",
    "                'on_road', 'off_road', 'Flat Section', 'Steep Section']\n",
    "\n",
    "cluster_profiles = df.groupby('cluster')[key_features].agg(['mean', 'median', 'std']).round(2)\n",
    "\n",
    "print(\"=\" * 120)\n",
    "print(\"CLUSTER PROFILES\")\n",
    "print(\"=\" * 120)\n",
    "print(cluster_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed cluster summary\n",
    "for cluster_id in range(final_k):\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"CLUSTER {cluster_id} - {len(cluster_data):,} routes ({len(cluster_data)/len(df)*100:.1f}%)\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Distance characteristics\n",
    "    print(f\"\\nüìè Distance:\")\n",
    "    print(f\"   Mean: {cluster_data['distance_m'].mean()/1000:.1f} km\")\n",
    "    print(f\"   Median: {cluster_data['distance_m'].median()/1000:.1f} km\")\n",
    "    print(f\"   Range: {cluster_data['distance_m'].min()/1000:.1f} - {cluster_data['distance_m'].max()/1000:.1f} km\")\n",
    "    \n",
    "    # Elevation characteristics\n",
    "    print(f\"\\n‚õ∞Ô∏è  Elevation:\")\n",
    "    print(f\"   Mean ascent: {cluster_data['ascent_m'].mean():.0f} m\")\n",
    "    print(f\"   Median ascent: {cluster_data['ascent_m'].median():.0f} m\")\n",
    "    \n",
    "    # Surface type (dominant)\n",
    "    print(f\"\\nüõ£Ô∏è  Surface:\")\n",
    "    print(f\"   On-road: {cluster_data['on_road'].mean():.1f}%\")\n",
    "    print(f\"   Off-road: {cluster_data['off_road'].mean():.1f}%\")\n",
    "    print(f\"   Paved Road: {cluster_data['Paved_Road'].mean():.1f}%\")\n",
    "    print(f\"   Gravel: {cluster_data['Gravel_Tracks'].mean():.1f}%\")\n",
    "    \n",
    "    # Gradient profile\n",
    "    print(f\"\\nüìê Gradient:\")\n",
    "    print(f\"   Flat: {cluster_data['Flat Section'].mean():.1f}%\")\n",
    "    print(f\"   Moderate: {cluster_data['Moderate Section'].mean():.1f}%\")\n",
    "    print(f\"   Steep: {cluster_data['Steep Section'].mean():.1f}%\")\n",
    "    \n",
    "    # Example routes\n",
    "    print(f\"\\nüìã Sample routes:\")\n",
    "    sample_routes = cluster_data.head(5)[['id', 'name', 'distance_m', 'ascent_m']]\n",
    "    for idx, route in sample_routes.iterrows():\n",
    "        print(f\"   ‚Ä¢ {route['name'][:60]} (ID: {route['id']}, {route['distance_m']/1000:.1f}km, {route['ascent_m']:.0f}m ascent)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Cluster Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Distance vs Ascent by Cluster\n",
    "for cluster_id in range(final_k):\n",
    "    cluster_data = df[df['cluster'] == cluster_id]\n",
    "    axes[0, 0].scatter(\n",
    "        cluster_data['distance_m'] / 1000, \n",
    "        cluster_data['ascent_m'],\n",
    "        label=f'Cluster {cluster_id}',\n",
    "        alpha=0.5,\n",
    "        s=10\n",
    "    )\n",
    "axes[0, 0].set_xlabel('Distance (km)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Ascent (m)', fontsize=12)\n",
    "axes[0, 0].set_title('Clusters: Distance vs Elevation', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cluster size distribution\n",
    "cluster_sizes = df['cluster'].value_counts().sort_index()\n",
    "axes[0, 1].bar(cluster_sizes.index, cluster_sizes.values, color=sns.color_palette(\"husl\", final_k))\n",
    "axes[0, 1].set_xlabel('Cluster ID', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Number of Routes', fontsize=12)\n",
    "axes[0, 1].set_title('Cluster Size Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Average distance by cluster\n",
    "avg_distance = df.groupby('cluster')['distance_m'].mean() / 1000\n",
    "axes[1, 0].bar(avg_distance.index, avg_distance.values, color=sns.color_palette(\"husl\", final_k))\n",
    "axes[1, 0].set_xlabel('Cluster ID', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Average Distance (km)', fontsize=12)\n",
    "axes[1, 0].set_title('Average Distance by Cluster', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: On-road vs Off-road by cluster\n",
    "surface_data = df.groupby('cluster')[['on_road', 'off_road']].mean()\n",
    "x = np.arange(final_k)\n",
    "width = 0.35\n",
    "axes[1, 1].bar(x - width/2, surface_data['on_road'], width, label='On-road', alpha=0.8)\n",
    "axes[1, 1].bar(x + width/2, surface_data['off_road'], width, label='Off-road', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Cluster ID', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Percentage (%)', fontsize=12)\n",
    "axes[1, 1].set_title('Surface Type by Cluster', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_characteristics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Cluster visualization saved as 'cluster_characteristics.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model and Cluster Labels\n",
    "\n",
    "Save the trained k-means model for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-means model\n",
    "joblib.dump(kmeans_final, 'kmeans.pkl')\n",
    "print(f\"‚úÖ K-means model saved as 'kmeans.pkl'\")\n",
    "print(f\"   Clusters: {final_k}\")\n",
    "print(f\"   Inertia: {kmeans_final.inertia_:.2f}\")\n",
    "\n",
    "# Save cluster-labeled data\n",
    "df.to_csv('Data_Engineered_with_clusters.csv', index=False)\n",
    "print(f\"\\n‚úÖ Data with cluster labels saved as 'Data_Engineered_with_clusters.csv'\")\n",
    "\n",
    "# Save cluster profiles for reference\n",
    "cluster_profiles.to_csv('cluster_profiles.csv')\n",
    "print(f\"‚úÖ Cluster profiles saved as 'cluster_profiles.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps: Manual Labeling\n",
    "\n",
    "Based on the cluster profiles above, manually assign descriptive labels to each cluster.\n",
    "\n",
    "**Example labels:**\n",
    "- Cluster 0: \"Short flat city rides\"\n",
    "- Cluster 1: \"Long mountain climbs\"\n",
    "- Cluster 2: \"Moderate suburban routes\"\n",
    "- etc.\n",
    "\n",
    "Create a mapping dictionary that can be used in production:\n",
    "\n",
    "```python\n",
    "CLUSTER_LABELS = {\n",
    "    0: \"Short flat city rides\",\n",
    "    1: \"Long mountain climbs\",\n",
    "    # ... add more\n",
    "}\n",
    "```\n",
    "\n",
    "**For curveball recommendations:**\n",
    "1. User uploads GPX ‚Üí extract features\n",
    "2. Predict cluster: `user_cluster = kmeans.predict(scaled_features)`\n",
    "3. Get 5 KNN recommendations (existing flow)\n",
    "4. Get 1 curveball from different cluster: \n",
    "   - Filter routes where `cluster != user_cluster`\n",
    "   - Find nearest route from that filtered set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Outputs:**\n",
    "- `kmeans.pkl`: Trained k-means model\n",
    "- `Data_Engineered_with_clusters.csv`: Full dataset with cluster labels\n",
    "- `cluster_profiles.csv`: Statistical profiles of each cluster\n",
    "- `kmeans_evaluation_metrics.png`: Metric comparison plots\n",
    "- `cluster_characteristics.png`: Cluster visualization plots\n",
    "\n",
    "**Files to deploy:**\n",
    "- `kmeans.pkl` ‚Üí Copy to `cycle_more/api_faf/app/`\n",
    "- Cluster labels dictionary ‚Üí Add to service code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
